{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Google Play store apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import os\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>I like eat delicious food. That's I'm cooking ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>This help eating healthy exercise regular basis</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.288462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Works great especially going grocery store</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Best idea us</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Best way</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Amazing</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Looking forward app,</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>It helpful site ! It help foods get !</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>good you.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Useful information The amount spelling errors ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      App                                  Translated_Review  \\\n",
       "0   10 Best Foods for You  I like eat delicious food. That's I'm cooking ...   \n",
       "1   10 Best Foods for You    This help eating healthy exercise regular basis   \n",
       "3   10 Best Foods for You         Works great especially going grocery store   \n",
       "4   10 Best Foods for You                                       Best idea us   \n",
       "5   10 Best Foods for You                                           Best way   \n",
       "6   10 Best Foods for You                                            Amazing   \n",
       "8   10 Best Foods for You                               Looking forward app,   \n",
       "9   10 Best Foods for You              It helpful site ! It help foods get !   \n",
       "10  10 Best Foods for You                                          good you.   \n",
       "11  10 Best Foods for You  Useful information The amount spelling errors ...   \n",
       "\n",
       "   Sentiment  Sentiment_Polarity  Sentiment_Subjectivity  \n",
       "0   Positive                1.00                0.533333  \n",
       "1   Positive                0.25                0.288462  \n",
       "3   Positive                0.40                0.875000  \n",
       "4   Positive                1.00                0.300000  \n",
       "5   Positive                1.00                0.300000  \n",
       "6   Positive                0.60                0.900000  \n",
       "8    Neutral                0.00                0.000000  \n",
       "9    Neutral                0.00                0.000000  \n",
       "10  Positive                0.70                0.600000  \n",
       "11  Positive                0.20                0.100000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('googleplaystore_user_reviews.csv')\n",
    "reviews = reviews.dropna()\n",
    "reviews.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data cleaning & wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode sentiment into numeric values\n",
    "conditions = [\n",
    "    (reviews['Sentiment'] == 'Positive'),\n",
    "    (reviews['Sentiment'] == 'Neutral'),\n",
    "    (reviews['Sentiment'] == 'Negative')]\n",
    "\n",
    "choices = [1, 0, -1]\n",
    "reviews['Sentiment_encode'] = np.select(conditions, choices, default= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    23998\n",
       "-1     8271\n",
       " 0     5158\n",
       "Name: Sentiment_encode, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the sentiment distribution\n",
    "reviews.Sentiment_encode.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text data\n",
    "def clean_text(sentence):\n",
    "    sent = sentence.lower()  # lowercase\n",
    "    sent = re.sub(r'[^\\w\\s]',' ',sent) # remove punctuation\n",
    "    sent = sent.replace(os.linesep,\"\")  # remove line break\n",
    "    sent = re.sub(r'\\d+','',sent)  # remove digits\n",
    "#     sent = ' '.join([tok for tok in sent.split() if tok not in STOP_WORDS]) # remove stopwords vs. with stopwords\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "      <th>Sentiment_encode</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>I like eat delicious food. That's I'm cooking ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1</td>\n",
       "      <td>i like eat delicious food  that s i m cooking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>This help eating healthy exercise regular basis</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>1</td>\n",
       "      <td>this help eating healthy exercise regular basis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Works great especially going grocery store</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1</td>\n",
       "      <td>works great especially going grocery store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Best idea us</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>best idea us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 Best Foods for You</td>\n",
       "      <td>Best way</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>best way</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     App                                  Translated_Review  \\\n",
       "0  10 Best Foods for You  I like eat delicious food. That's I'm cooking ...   \n",
       "1  10 Best Foods for You    This help eating healthy exercise regular basis   \n",
       "3  10 Best Foods for You         Works great especially going grocery store   \n",
       "4  10 Best Foods for You                                       Best idea us   \n",
       "5  10 Best Foods for You                                           Best way   \n",
       "\n",
       "  Sentiment  Sentiment_Polarity  Sentiment_Subjectivity Sentiment_encode  \\\n",
       "0  Positive                1.00                0.533333                1   \n",
       "1  Positive                0.25                0.288462                1   \n",
       "3  Positive                0.40                0.875000                1   \n",
       "4  Positive                1.00                0.300000                1   \n",
       "5  Positive                1.00                0.300000                1   \n",
       "\n",
       "                                             reviews  \n",
       "0  i like eat delicious food  that s i m cooking ...  \n",
       "1    this help eating healthy exercise regular basis  \n",
       "3         works great especially going grocery store  \n",
       "4                                       best idea us  \n",
       "5                                           best way  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['reviews'] = reviews['Translated_Review'].apply(clean_text)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8671     been using paid version years now  originally ...\n",
       "29070    i love app  using ages  however latest ver   s...\n",
       "58115    i hate  weeks waiting items i find not getting...\n",
       "12111                                             the best\n",
       "2609     new tos data collection   i m out     uninstal...\n",
       "Name: reviews, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews['reviews'],reviews['Sentiment_encode'],test_size = 0.3, random_state=0)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Polarity</th>\n",
       "      <th>Sentiment_Subjectivity</th>\n",
       "      <th>Sentiment_encode</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>Apex Launcher</td>\n",
       "      <td>Been using paid version years now. Originally ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>1</td>\n",
       "      <td>been using paid version years now  originally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29070</th>\n",
       "      <td>ConvertPad - Unit Converter</td>\n",
       "      <td>I love app, using ages, however latest ver 3.1...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1</td>\n",
       "      <td>i love app  using ages  however latest ver   s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58115</th>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>I hate 2 weeks waiting items I find NOT gettin...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>-1</td>\n",
       "      <td>i hate  weeks waiting items i find not getting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12111</th>\n",
       "      <td>Bagan - Myanmar Keyboard</td>\n",
       "      <td>The best</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>the best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>AC - Tips &amp; News for Android™</td>\n",
       "      <td>New TOS data collection.. I'm out!!! (Uninstal...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.266335</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1</td>\n",
       "      <td>new tos data collection   i m out     uninstal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 App  \\\n",
       "8671                   Apex Launcher   \n",
       "29070    ConvertPad - Unit Converter   \n",
       "58115                            H&M   \n",
       "12111       Bagan - Myanmar Keyboard   \n",
       "2609   AC - Tips & News for Android™   \n",
       "\n",
       "                                       Translated_Review Sentiment  \\\n",
       "8671   Been using paid version years now. Originally ...  Positive   \n",
       "29070  I love app, using ages, however latest ver 3.1...  Positive   \n",
       "58115  I hate 2 weeks waiting items I find NOT gettin...  Negative   \n",
       "12111                                           The best  Positive   \n",
       "2609   New TOS data collection.. I'm out!!! (Uninstal...  Positive   \n",
       "\n",
       "       Sentiment_Polarity  Sentiment_Subjectivity Sentiment_encode  \\\n",
       "8671             0.340000                0.680000                1   \n",
       "29070            0.425000                0.550000                1   \n",
       "58115           -0.900000                0.950000               -1   \n",
       "12111            1.000000                0.300000                1   \n",
       "2609             0.266335                0.454545                1   \n",
       "\n",
       "                                                 reviews  \n",
       "8671   been using paid version years now  originally ...  \n",
       "29070  i love app  using ages  however latest ver   s...  \n",
       "58115  i hate  weeks waiting items i find not getting...  \n",
       "12111                                           the best  \n",
       "2609   new tos data collection   i m out     uninstal...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(reviews,test_size = 0.3, random_state=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted values: [-1  0 -1 ...  1 -1  1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8831596758393445"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic regression\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "text_clf_LR = Pipeline([('vect', CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', LogisticRegression())])\n",
    "\n",
    "text_clf_LR.fit(train.reviews.values, train.Sentiment_encode.astype('int')) \n",
    "predicted_LR = text_clf_LR.predict(test.reviews.values)\n",
    "\n",
    "print('predicted values:',predicted_LR)\n",
    "accuracy_score(predicted_LR, test.Sentiment_encode.astype('int'))   # logistic regression 有0.87 accuracy\n",
    "# accuracy_score(predicted_LR, X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>N-gram with logistic regression：（-> unigram with stopwords效果最好）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['analyzer', 'binary', 'decode_error', 'dtype', 'encoding', 'input', 'lowercase', 'max_df', 'max_features', 'min_df', 'ngram_range', 'preprocessor', 'stop_words', 'strip_accents', 'token_pattern', 'tokenizer', 'vocabulary'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "CountVectorizer().get_params().keys() # check the available params of CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted values: [-1  0 -1 ...  1 -1  1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8859203847181405"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare accuracy of unigram, bigram, trigram\n",
    "\n",
    "cvec = CountVectorizer()\n",
    "lr = LogisticRegression()\n",
    "n_features = np.arange(10000,100001,10000)  # 这里我只取了10000作为max_features\n",
    "\n",
    "# cvec.set_params(stop_words = STOP_WORDS, max_features=10000, ngram_range=(1,1))    # unigram without stopwords: 0.8721\n",
    "# cvec.set_params(max_features=10000, ngram_range=(1,2))  # bigram without stopwords: 0.87024\n",
    "# cvec.set_params(max_features=10000, ngram_range=(1,3))  # trigram without stopwords: 0.8705\n",
    "\n",
    "text_clf_LR = Pipeline([('vect', cvec),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', LogisticRegression())])\n",
    "\n",
    "text_clf_LR.fit(train.reviews.values, train.Sentiment_encode.astype('int')) \n",
    "predicted_LR = text_clf_LR.predict(test.reviews.values)\n",
    "print('predicted values:',predicted_LR)\n",
    "accuracy_score(predicted_LR, test.Sentiment_encode.astype('int'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17616"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of features of Count vectorizer\n",
    "len(cvec.get_feature_names())   # 总共有17616个features在count vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer()的params: 排除了stopwords之后，unigram的表现最好，好于bigram和trigram\n",
    "- 有stopwords跟排除stopwords结果差不多；\n",
    "- max_features增加，accuracy反而下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO： plot出unigram, bigram, trigram比较图(iterate over num. of features)\n",
    "# 参考：https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-4-count-vectorizer-b3f4944e51b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TfidfVectorizer() vs. CountVectorizer() (-> 没有显著差别）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['analyzer', 'binary', 'decode_error', 'dtype', 'encoding', 'input', 'lowercase', 'max_df', 'max_features', 'min_df', 'ngram_range', 'norm', 'preprocessor', 'smooth_idf', 'stop_words', 'strip_accents', 'sublinear_tf', 'token_pattern', 'tokenizer', 'use_idf', 'vocabulary'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TfidfVectorizer().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted values: [ 0 -1 -1 ...  1 -1  1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8721168403241607"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tvec = TfidfVectorizer()\n",
    "lr = LogisticRegression()\n",
    "\n",
    "tvec.set_params(stop_words = STOP_WORDS, max_features=10000, ngram_range=(1,1))  # unigram  -> o.8721\n",
    "# tvec.set_params(stop_words = STOP_WORDS, max_features=10000, ngram_range=(1,2))  # bigram  -> 0.87024\n",
    "\n",
    "text_clf_LR_tfidf = Pipeline([('vect', tvec),\n",
    "                         ('clf', LogisticRegression())])\n",
    "\n",
    "text_clf_LR_tfidf.fit(train.reviews.values, train.Sentiment_encode.astype('int')) \n",
    "predicted_LR = text_clf_LR_tfidf.predict(test.reviews.values)\n",
    "print('predicted values:',predicted_LR)\n",
    "accuracy_score(predicted_LR, test.Sentiment_encode.astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前用CountVectorizer()是pipeline包含了tf-idf transformer的，所以performance跟使用tdidfVectorizer()效果一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of features of tfidf vectorizer\n",
    "len(tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个tfidf vectorizer一共有10000 features (之前设param时定义10000 作为 max_feature value）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT FOR TRIGRAM WITH STOP WORDS (Tfidf)\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nfeature_accuracy_checker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nfeature_accuracy_checker' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"RESULT FOR TRIGRAM WITH STOP WORDS (Tfidf)\\n\")\n",
    "feature_result_tgt = nfeature_accuracy_checker(vectorizer=tvec,ngram_range=(1, 3))  # trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Other Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted values: [ 0 -1 -1 ...  1 -1  1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9244812538961618"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "tvec = TfidfVectorizer()\n",
    "svc = LinearSVC()\n",
    "\n",
    "# tvec.set_params(stop_words = STOP_WORDS, max_features=10000, ngram_range=(1,1))  # unigram -> 0.893\n",
    "tvec.set_params(max_features=10000, ngram_range=(1,3))  # trigram -> 0.8941 accuracy\n",
    "\n",
    "text_clf_svc_tfidf = Pipeline([('vect', tvec),\n",
    "                         ('clf', LinearSVC())])\n",
    "\n",
    "text_clf_svc_tfidf.fit(train.reviews.values, train.Sentiment_encode.astype('int')) \n",
    "predicted_svc = text_clf_svc_tfidf.predict(test.reviews.values)\n",
    "print('predicted values:',predicted_svc)\n",
    "accuracy_score(predicted_svc, test.Sentiment_encode.astype('int'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted values: [ 0  1 -1 ...  1  1  1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8774601478315077"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RidgeClassifier()\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "tvec = TfidfVectorizer()\n",
    "rc = RidgeClassifier()\n",
    "\n",
    "# tvec.set_params(stop_words = STOP_WORDS, max_features=10000, ngram_range=(1,1))   # unigram: 0.844\n",
    "tvec.set_params(max_features=10000, ngram_range=(1,2)) # bigram: 0.856\n",
    "\n",
    "text_clf_rc_tfidf = Pipeline([('vect', tvec),\n",
    "                         ('clf', RidgeClassifier())])\n",
    "\n",
    "text_clf_rc_tfidf.fit(train.reviews.values, train.Sentiment_encode.astype('int')) \n",
    "predicted_rc = text_clf_rc_tfidf.predict(test.reviews.values)\n",
    "print('predicted values:',predicted_rc)\n",
    "accuracy_score(predicted_rc, test.Sentiment_encode.astype('int'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted values: [ 0 -1 -1 ...  1 -1  1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9254608602725087"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PassiveAggressiveClassifier()\n",
    "\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "tvec = TfidfVectorizer()\n",
    "pac = PassiveAggressiveClassifier()\n",
    "\n",
    "# tvec.set_params(stop_words = STOP_WORDS, max_features=10000, ngram_range=(1,1))  # unigram: 0.893\n",
    "tvec.set_params(max_features=10000, ngram_range=(1,2))    # bigram: 0.895 (max)\n",
    "\n",
    "text_clf_pac_tfidf = Pipeline([('vect', tvec),\n",
    "                         ('clf', PassiveAggressiveClassifier())])\n",
    "\n",
    "text_clf_pac_tfidf.fit(train.reviews.values, train.Sentiment_encode.astype('int')) \n",
    "predicted_pac = text_clf_pac_tfidf.predict(test.reviews.values)\n",
    "print('predicted values:',predicted_pac)\n",
    "accuracy_score(predicted_pac, test.Sentiment_encode.astype('int'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>结果:</h4> \n",
    "linear_SVC(trigram:0.894) | PassiveAggressiveClassifier(bigram:0.895) | Logistic_regression (unigram: 0.87021) | Ridge Classifier (bigram: 0.856) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Ensemble classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结合上面几个performance比较好的classifier,去建一个ensemble classifier。再看performance是否变好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此function用于比较pipeline classifier, 基于accuracy和training time (TODO：内部结构待弄懂)\n",
    "\n",
    "from time import time\n",
    "\n",
    "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    if len(x_test[y_test == 0]) / (len(x_test)*1.) > 0.5:\n",
    "        null_accuracy = len(x_test[y_test == 0]) / (len(x_test)*1.)\n",
    "    else:\n",
    "        null_accuracy = 1. - (len(x_test[y_test == 0]) / (len(x_test)*1.))\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print (\"null accuracy: {0:.2f}%\".format(null_accuracy*100))\n",
    "    print (\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
    "    if accuracy > null_accuracy:\n",
    "        print (\"model is {0:.2f}% more accurate than null accuracy\".format((accuracy-null_accuracy)*100))\n",
    "    elif accuracy == null_accuracy:\n",
    "        print (\"model has the same accuracy with the null accuracy\")\n",
    "    else:\n",
    "        print (\"model is {0:.2f}% less accurate than null accuracy\".format((null_accuracy-accuracy)*100))\n",
    "    print (\"train and test time: {0:.2f}s\".format(train_test_time))\n",
    "    print (\"-\"*80)\n",
    "    return accuracy, train_test_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result for Logistic Regression\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "null accuracy: 86.21%\n",
      "accuracy score: 87.02%\n",
      "model is 0.81% more accurate than null accuracy\n",
      "train and test time: 2.74s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Linear SVC\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "null accuracy: 86.21%\n",
      "accuracy score: 89.34%\n",
      "model is 3.13% more accurate than null accuracy\n",
      "train and test time: 2.98s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for LinearSVC with L1-based feature selection\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "null accuracy: 86.21%\n",
      "accuracy score: 89.40%\n",
      "model is 3.19% more accurate than null accuracy\n",
      "train and test time: 4.37s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Multinomial NB\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "null accuracy: 86.21%\n",
      "accuracy score: 73.57%\n",
      "model is 12.65% less accurate than null accuracy\n",
      "train and test time: 2.38s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Ridge Classifier\n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "        tol=0.001)\n",
      "null accuracy: 86.21%\n",
      "accuracy score: 85.67%\n",
      "model is 0.54% less accurate than null accuracy\n",
      "train and test time: 3.35s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Passive-Aggresive\n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              fit_intercept=True, loss='hinge', max_iter=None, n_iter=None,\n",
      "              n_jobs=1, random_state=None, shuffle=True, tol=None,\n",
      "              verbose=0, warm_start=False)\n",
      "null accuracy: 86.21%\n",
      "accuracy score: 89.39%\n",
      "model is 3.18% more accurate than null accuracy\n",
      "train and test time: 2.36s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Logistic Regression', 0.8702466826965892, 2.736386775970459),\n",
       " ('Linear SVC', 0.8934010152284264, 2.980360269546509),\n",
       " ('LinearSVC with L1-based feature selection',\n",
       "  0.8940244011042836,\n",
       "  4.372558116912842),\n",
       " ('Multinomial NB', 0.735684388636566, 2.384187936782837),\n",
       " ('Ridge Classifier', 0.8567103036779766, 3.3471240997314453),\n",
       " ('Passive-Aggresive', 0.8939353459791611, 2.3561630249023438)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the accuracy and training time for each classifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "names = [\"Logistic Regression\", \"Linear SVC\", \"LinearSVC with L1-based feature selection\",\"Multinomial NB\", \n",
    "         \"Ridge Classifier\", \"Passive-Aggresive\"]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    LinearSVC(),\n",
    "    Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))]),\n",
    "    MultinomialNB(),\n",
    "    RidgeClassifier(),\n",
    "    PassiveAggressiveClassifier()\n",
    "    ]\n",
    "\n",
    "zipped_clf = zip(names,classifiers)\n",
    "tvec = TfidfVectorizer()\n",
    "\n",
    "def classifier_comparator(vectorizer=tvec, n_features=10000, stop_words=None, ngram_range=(1, 1), classifier=zipped_clf):\n",
    "    result = []\n",
    "    vectorizer.set_params(stop_words=STOP_WORDS, max_features=n_features, ngram_range=ngram_range)\n",
    "    for n,c in classifier:\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', c)\n",
    "        ])\n",
    "        print (\"Validation result for {}\".format(n))\n",
    "        print (c)\n",
    "#         clf_accuracy,tt_time = accuracy_summary(checker_pipeline, x_train, y_train, x_validation, y_validation)\n",
    "        clf_accuracy,tt_time = accuracy_summary(checker_pipeline,train.reviews.values, train.Sentiment_encode.astype('int'), test.reviews.values, test.Sentiment_encode.astype('int'))\n",
    "        result.append((n,clf_accuracy,tt_time))\n",
    "    return result\n",
    "\n",
    "bigram_result = classifier_comparator(n_features=10000,ngram_range=(1,2))\n",
    "bigram_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result for Logistic Regression\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "null accuracy: 86.21%\n",
      "accuracy score: 88.90%\n",
      "model is 2.69% more accurate than null accuracy\n",
      "train and test time: 3.18s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Linear SVC\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "null accuracy: 86.21%\n",
      "accuracy score: 92.51%\n",
      "model is 6.30% more accurate than null accuracy\n",
      "train and test time: 2.83s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Multinomial NB\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "null accuracy: 86.21%\n",
      "accuracy score: 74.01%\n",
      "model is 12.20% less accurate than null accuracy\n",
      "train and test time: 2.42s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Ridge Classifier\n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "        tol=0.001)\n",
      "null accuracy: 86.21%\n",
      "accuracy score: 87.75%\n",
      "model is 1.53% more accurate than null accuracy\n",
      "train and test time: 3.50s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Passive Aggresive Classifier\n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              fit_intercept=True, loss='hinge', max_iter=None, n_iter=None,\n",
      "              n_jobs=1, random_state=None, shuffle=True, tol=None,\n",
      "              verbose=0, warm_start=False)\n",
      "null accuracy: 86.21%\n",
      "accuracy score: 92.63%\n",
      "model is 6.41% more accurate than null accuracy\n",
      "train and test time: 2.51s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Ensemble\n",
      "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)), ('svc', Linear...   n_jobs=1, random_state=None, shuffle=True, tol=None,\n",
      "              verbose=0, warm_start=False))],\n",
      "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)\n",
      "null accuracy: 86.21%\n",
      "accuracy score: 90.73%\n",
      "model is 4.52% more accurate than null accuracy\n",
      "train and test time: 4.61s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# compare results of each classifier and emsemble classifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = LinearSVC()\n",
    "clf3 = MultinomialNB()\n",
    "clf4 = RidgeClassifier()\n",
    "clf5 = PassiveAggressiveClassifier()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('svc', clf2), ('mnb', clf3), ('rcs', clf4), ('pac', clf5)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, eclf], ['Logistic Regression', 'Linear SVC', 'Multinomial NB', 'Ridge Classifier', 'Passive Aggresive Classifier', 'Ensemble']):\n",
    "    checker_pipeline = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer(max_features=10000,ngram_range=(1, 2))),\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "    print (\"Validation result for {}\".format(label))\n",
    "    print (clf)\n",
    "#     clf_accuracy,tt_time = accuracy_summary(checker_pipeline, x_train, y_train, x_validation, y_validation)\n",
    "    clf_accuracy,tt_time = accuracy_summary(checker_pipeline,train.reviews.values, train.Sentiment_encode.astype('int'), test.reviews.values, test.Sentiment_encode.astype('int'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：LinearSVC and Passive Aggresive classifier yield the best performance ~92% accuracy, even better than the voting classifier(emsemble) of 90% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*P.s: 在此project, 将tutorial中的x_train 改为train.reviews.values，y_train改为 train.Sentiment_encode.astype('int') 即可；<br>\n",
    "test data同理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute positive, negative proportion for each word (tutorial Part 5)\n",
    "# 目的是用于lexical approach for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledSentence(words=['i', 'like', 'eat', 'delicious', 'food', 'that', 's', 'i', 'm', 'cooking', 'food', 'myself', 'case', 'best', 'foods', 'helps', 'lot', 'also', 'best', 'before', 'shelf', 'life'], tags=['all_0']),\n",
       " LabeledSentence(words=['this', 'help', 'eating', 'healthy', 'exercise', 'regular', 'basis'], tags=['all_1']),\n",
       " LabeledSentence(words=['works', 'great', 'especially', 'going', 'grocery', 'store'], tags=['all_3']),\n",
       " LabeledSentence(words=['best', 'idea', 'us'], tags=['all_4']),\n",
       " LabeledSentence(words=['best', 'way'], tags=['all_5'])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "def labelize_tweets_ug(reviews,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, r in zip(reviews.index, reviews):\n",
    "        result.append(LabeledSentence(r.split(), [prefix + '_%s' % i]))\n",
    "    return result\n",
    "\n",
    "all_x_w2v = labelize_tweets_ug(reviews.reviews, 'all')\n",
    "all_x_w2v[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 1. DBOW (Distributed Bag Of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37427/37427 [00:00<00:00, 1864107.44it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2350355.08it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1669949.00it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2193962.57it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2491116.79it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2165274.22it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1676243.63it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2118234.17it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2254491.11it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1995020.92it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1991452.37it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2157418.14it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2122071.18it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2071006.42it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2114752.81it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2379822.26it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2397596.23it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2371194.90it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2035188.78it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1567889.33it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2171444.20it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2236185.41it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2014814.16it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1970974.26it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2149854.36it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2435047.63it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2249354.71it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1923376.45it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2415712.04it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2318009.15it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2320167.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7291833645026271"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm  # Instantly make your loops show a smart progress meter\n",
    "from sklearn import utils\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model_ug_dbow = Doc2Vec(dm=0, size=100, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dbow.build_vocab([x for x in tqdm(all_x_w2v)])   \n",
    "\n",
    "for epoch in range(30):\n",
    "    model_ug_dbow.train(utils.shuffle([x for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_dbow.alpha -= 0.002\n",
    "    model_ug_dbow.min_alpha = model_ug_dbow.alpha\n",
    "    \n",
    "\n",
    "def get_vectors(model, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = model.docvecs[prefix]\n",
    "        n += 1\n",
    "    return vecs\n",
    "\n",
    "train_vecs_dbow = get_vectors(model_ug_dbow, train.reviews, 100)\n",
    "validation_vecs_dbow = get_vectors(model_ug_dbow, test.reviews, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow, train.Sentiment_encode.astype('int'))\n",
    "clf.score(validation_vecs_dbow, test.Sentiment_encode.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar words of \"bad\":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('forwarded', 0.3656032979488373),\n",
       " ('uk', 0.36158841848373413),\n",
       " ('avoidable', 0.33633190393447876),\n",
       " ('vivid', 0.3328895568847656),\n",
       " ('escape', 0.3306964635848999),\n",
       " ('trademark', 0.32639646530151367),\n",
       " ('ingame', 0.3126377761363983),\n",
       " ('crippled', 0.31262779235839844),\n",
       " ('guild', 0.30945926904678345),\n",
       " ('fpl', 0.30623435974121094)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('similar words of \"bad\":')\n",
    "model_ug_dbow.most_similar('bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 2.DMC (Distributed Memory Concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37427/37427 [00:00<00:00, 1331356.25it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2377947.68it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1934016.06it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2249902.77it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2066997.81it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2468281.20it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2496306.21it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2209526.31it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2423095.10it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2405679.59it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2297686.16it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2437316.07it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2286874.54it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2287141.09it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2347859.23it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2479744.35it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2272440.88it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2318899.43it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2462782.44it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2306361.89it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2322914.16it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2496822.37it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2367297.26it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2328288.80it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2396717.70it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1893495.15it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2107145.27it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1489870.60it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2284079.50it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2532796.85it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2323773.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6722771395493811"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_ug_dmc = Doc2Vec(dm=1, dm_concat=1, size=100, window=2, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dmc.build_vocab([x for x in tqdm(all_x_w2v)])  # 唯一差别在 dm_concat\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_ug_dmc.train(utils.shuffle([x for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_dmc.alpha -= 0.002\n",
    "    model_ug_dmc.min_alpha = model_ug_dmc.alpha\n",
    "    \n",
    "train_vecs_dmc = get_vectors(model_ug_dmc, train.reviews, 100)\n",
    "validation_vecs_dmc = get_vectors(model_ug_dmc, test.reviews, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmc, train.Sentiment_encode.astype('int'))\n",
    "clf.score(validation_vecs_dmc, test.Sentiment_encode.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar words of \"good\":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('great', 0.7518031001091003),\n",
       " ('thry', 0.6072913408279419),\n",
       " ('clinique', 0.5614951848983765),\n",
       " ('stupidest', 0.5548834800720215),\n",
       " ('neat', 0.5425306558609009),\n",
       " ('witness', 0.5417161583900452),\n",
       " ('decent', 0.5402413606643677),\n",
       " ('geat', 0.5385168790817261),\n",
       " ('scratchy', 0.5356041193008423),\n",
       " ('hurts', 0.5325502753257751)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('similar words of \"good\":')\n",
    "model_ug_dmc.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('splash', 0.5270482301712036),\n",
       " ('leveling', 0.44908684492111206),\n",
       " ('newspaper', 0.4096541404724121),\n",
       " ('chicago', 0.40174418687820435),\n",
       " ('aesthetics', 0.4013820290565491),\n",
       " ('rain', 0.3991454839706421),\n",
       " ('freshen', 0.39377665519714355),\n",
       " ('predictive', 0.3799162805080414),\n",
       " ('scanning', 0.3793656527996063),\n",
       " ('preview', 0.3772611618041992)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ug_dmc.most_similar(positive=['bigger','small'],negative=['big'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 3. DMM (Distributed Memory Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37427/37427 [00:00<00:00, 1648034.35it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1820461.50it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2301324.03it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2504470.58it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2416381.37it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1199475.95it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1783420.23it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2055764.28it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2450977.64it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2384159.53it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2331158.54it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2320339.02it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2168025.41it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1996873.49it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2192308.02it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2163155.79it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1512027.58it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2010118.65it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2020779.52it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1933492.00it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2313874.91it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2272440.88it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2291347.48it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2256046.33it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2155315.04it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2268959.27it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2344002.86it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2298258.02it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2212266.46it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2309653.45it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2309585.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6989936770861163"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_ug_dmm = Doc2Vec(dm=1, dm_mean=1, size=100, window=4, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_ug_dmm.build_vocab([x for x in tqdm(all_x_w2v)])  #主要差别在 dm_mean\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_ug_dmm.train(utils.shuffle([x for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
    "    model_ug_dmm.alpha -= 0.002\n",
    "    model_ug_dmm.min_alpha = model_ug_dmm.alpha\n",
    "    \n",
    "train_vecs_dmm = get_vectors(model_ug_dmm, train.reviews, 100)\n",
    "validation_vecs_dmm = get_vectors(model_ug_dmm, test.reviews, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmm, train.Sentiment_encode.astype('int'))\n",
    "clf.score(validation_vecs_dmm, test.Sentiment_encode.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar words of \"bad\":\n",
      "[('good', 0.5336456298828125), ('terrible', 0.4774276614189148), ('disappointed', 0.46820715069770813), ('cool', 0.4678190350532532), ('poor', 0.45678606629371643), ('annoying', 0.4399759769439697), ('addictive', 0.4396994709968567), ('horrible', 0.4269152879714966), ('addicting', 0.4016854763031006), ('worst', 0.3992973566055298)]\n",
      "------------------------\n",
      "similar words of \"good\":\n",
      "[('great', 0.7672052383422852), ('amazing', 0.6220297813415527), ('awesome', 0.6112433075904846), ('nice', 0.5685214996337891), ('excellent', 0.5373982787132263), ('bad', 0.5336456298828125), ('love', 0.5319488644599915), ('best', 0.5261752605438232), ('fun', 0.5221210718154907), ('cool', 0.5194724798202515)]\n"
     ]
    }
   ],
   "source": [
    "print('similar words of \"bad\":')\n",
    "print(model_ug_dmm.most_similar('bad'))\n",
    "print('------------------------')\n",
    "print('similar words of \"good\":')\n",
    "print(model_ug_dmm.most_similar('good'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析：the system successfully capture similar words of \"good\", yet fails to capture similar words of \"bad\" and it recognizes \"good\" as a similar wods of \"bad\"m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 4. Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7443227357734438"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DBOW + DMC\n",
    "def get_concat_vectors(model1,model2, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = np.append(model1.docvecs[prefix],model2.docvecs[prefix])\n",
    "        n += 1\n",
    "    return vecs\n",
    "\n",
    "train_vecs_dbow_dmc = get_concat_vectors(model_ug_dbow,model_ug_dmc, train.reviews, 200)\n",
    "validation_vecs_dbow_dmc = get_concat_vectors(model_ug_dbow,model_ug_dmc, test.reviews, 200)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_dmc, train.Sentiment_encode.astype('int'))\n",
    "clf.score(validation_vecs_dbow_dmc, test.Sentiment_encode.astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析：Combined method has better performance than DMC: 0.663 and DBOW: 0.723 separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7535844687861787"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DBOW and DMM\n",
    "train_vecs_dbow_dmm = get_concat_vectors(model_ug_dbow,model_ug_dmm, train.reviews, 200)\n",
    "validation_vecs_dbow_dmm = get_concat_vectors(model_ug_dbow,model_ug_dmm, test.reviews, 200)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_dmm, train.Sentiment_encode.astype('int'))\n",
    "clf.score(validation_vecs_dbow_dmm, test.Sentiment_encode.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Phrase modeling using Gensim </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genism工具 -> 可以extract meaningful bigram\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "tokenized_train = [t.split() for t in train.reviews]\n",
    "phrases = Phrases(tokenized_train)\n",
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['been_using', 'paid_version', 'years_now', 'originally', 'brilliant']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at how bigram works\n",
    "bigram[tokenized_train[0]][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用这个package可以recognize meaning bigram, e.g: paid, version 被当作 paid-vesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledSentence(words=['i', 'like', 'eat', 'delicious', 'food', 'that_s', 'i', 'm', 'cooking', 'food', 'myself', 'case', 'best', 'foods', 'helps_lot', 'also', 'best', 'before', 'shelf', 'life'], tags=['all_0']),\n",
       " LabeledSentence(words=['this', 'help', 'eating', 'healthy', 'exercise', 'regular_basis'], tags=['all_1']),\n",
       " LabeledSentence(words=['works', 'great', 'especially', 'going', 'grocery', 'store'], tags=['all_3']),\n",
       " LabeledSentence(words=['best', 'idea', 'us'], tags=['all_4']),\n",
       " LabeledSentence(words=['best', 'way'], tags=['all_5']),\n",
       " LabeledSentence(words=['amazing'], tags=['all_6']),\n",
       " LabeledSentence(words=['looking_forward', 'app'], tags=['all_8']),\n",
       " LabeledSentence(words=['it', 'helpful', 'site', 'it', 'help', 'foods', 'get'], tags=['all_9']),\n",
       " LabeledSentence(words=['good', 'you'], tags=['all_10']),\n",
       " LabeledSentence(words=['useful_information', 'the', 'amount', 'spelling', 'errors', 'questions', 'validity', 'information', 'shared', 'once', 'fixed', 'stars', 'given'], tags=['all_11'])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tansform corpus using bigram model\n",
    "\n",
    "def labelize_reviews_bg(reviews,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, r in zip(reviews.index, reviews):\n",
    "        result.append(LabeledSentence(bigram[r.split()], [prefix + '_%s' % i]))\n",
    "    return result\n",
    "  \n",
    "# all_x = pd.concat([x_train,x_validation,x_test])\n",
    "all_x_w2v_bg = labelize_reviews_bg(reviews.reviews, 'all')\n",
    "all_x_w2v_bg[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更多meaningful words are indentified, e.g. \"looking_forward\",\"useful_information\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37427/37427 [00:00<00:00, 1354235.03it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1672921.01it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2315342.42it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2219460.42it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2348983.46it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1648917.21it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1993855.30it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2077337.18it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2209650.72it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2401300.47it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2397303.32it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2040293.94it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2348596.89it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2063682.70it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2137617.49it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2441561.80it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2155907.05it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 1539761.41it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2164169.73it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2144186.96it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2191420.50it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2007137.31it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2354479.56it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2229104.35it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2122300.70it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2172165.32it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2274745.92it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2410740.91it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2168414.73it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2167426.73it/s]\n",
      "100%|██████████| 37427/37427 [00:00<00:00, 2388294.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7198325763647698"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DBOW (Distributed Bag Of Words) with bigram detected\n",
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dbow = Doc2Vec(dm=0, size=100, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_bg_dbow.build_vocab([x for x in tqdm(all_x_w2v_bg)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_bg_dbow.train(utils.shuffle([x for x in tqdm(all_x_w2v_bg)]), total_examples=len(all_x_w2v_bg), epochs=1)\n",
    "    model_bg_dbow.alpha -= 0.002\n",
    "    model_bg_dbow.min_alpha = model_bg_dbow.alpha\n",
    "\n",
    "train_vecs_dbow_bg = get_vectors(model_bg_dbow, train.reviews, 100)\n",
    "validation_vecs_dbow_bg = get_vectors(model_bg_dbow, test.reviews, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_bg, train.Sentiment_encode.astype('int'))\n",
    "clf.score(validation_vecs_dbow_bg, test.Sentiment_encode.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: DMC (Distributed Memory Concatenated) with bigram detected\n",
    "# TODO: DMM (Distributed Memory Mean) with bigram detected\n",
    "# TODO: Combined models\n",
    "# 都是用跟之前同样的方法 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO：trigram model: 方法同上 (只是使用trigram而已)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO：creating joint vectors across different n-grams\n",
    "# 使用performance最好的几个model, e.g:unigram DBOW model .join with. trigram DMM vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Part 8: dimension reduction: Chi2, PCA </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$\\\\chi^2$')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# chi2 for feature selection （plot the top 20 features）\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tvec = TfidfVectorizer(max_features=10000,ngram_range=(1, 3))  # 这里使用的是tri-gram\n",
    "x_train_tfidf = tvec.fit_transform(train.reviews)\n",
    "x_test_tfidf = tvec.transform(test.reviews)\n",
    "chi2score = chi2(x_train_tfidf, train.Sentiment_encode.astype('int'))[0]  #index 0 -> chi2 statistics of each feature\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "wscores = zip(tvec.get_feature_names(), chi2score)\n",
    "wchi2 = sorted(wscores, key=lambda x:x[1])  # 根据chi2score从小到大sort\n",
    "topchi2 = list(zip(*wchi2[-20:])) # 选top20 -> 倒着选\n",
    "\n",
    "# topchi2[0] #得到 a list of features (tokens)\n",
    "# topchi2[1]  #得到 a list of chi2 scores （对应每个token)\n",
    "\n",
    "x = range(len(topchi2[1])) \n",
    "labels = topchi2[0]\n",
    "plt.barh(x,topchi2[1], align='center', alpha=0.2)  # alpha调节透明度\n",
    "plt.plot(topchi2[1], x, '-o', markersize=5, alpha=0.8)\n",
    "plt.yticks(x, labels)\n",
    "plt.xlabel('$\\chi^2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过chi-2选出来的词, the most useful words有：good, great, worst, etc. 注意这里用reduced-size reviews来分析，总共有5000条。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2 feature selection evaluation calculated for 1000 features\n",
      "chi2 feature selection evaluation calculated for 2000 features\n",
      "chi2 feature selection evaluation calculated for 3000 features\n",
      "chi2 feature selection evaluation calculated for 4000 features\n",
      "chi2 feature selection evaluation calculated for 5000 features\n",
      "chi2 feature selection evaluation calculated for 6000 features\n",
      "chi2 feature selection evaluation calculated for 7000 features\n",
      "chi2 feature selection evaluation calculated for 8000 features\n",
      "chi2 feature selection evaluation calculated for 9000 features\n"
     ]
    }
   ],
   "source": [
    "# chi2 to reduce dimensions\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "ch2_result = []\n",
    "for n in np.arange(1000,10000,1000):\n",
    "    ch2 = SelectKBest(chi2, k=n)\n",
    "    x_train_chi2_selected = ch2.fit_transform(x_train_tfidf, train.Sentiment_encode.astype('int'))  # 后者只是y_train\n",
    "    x_test_chi2_selected = ch2.transform(x_test_tfidf)  # 注意test data只用transform, 不用fit （防止data leakage)\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(x_train_chi2_selected, train.Sentiment_encode.astype('int'))\n",
    "    score = clf.score(x_test_chi2_selected, test.Sentiment_encode.astype('int')) # 后者只是y_test而已\n",
    "    ch2_result.append(score)\n",
    "    print (\"chi2 feature selection evaluation calculated for {} features\".format(n))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Doc2vec (DBOW + DMC) : explained variance of components')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# use PCA to train Doc2vec -> DBOW (Distributed Bag Of Words) \n",
    "scaler = StandardScaler()\n",
    "d2v_dbow_dmc_std = scaler.fit_transform(train_vecs_dbow_dmc)\n",
    "d2v_dbow_dmc_std_val = scaler.fit_transform(validation_vecs_dbow_dmc)\n",
    "d2v_pca = PCA().fit(d2v_dbow_dmc_std)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "x_values = range(1, d2v_pca.n_components_+1)\n",
    "ax.plot(x_values, d2v_pca.explained_variance_ratio_, lw=2, label='explained variance')\n",
    "ax.plot(x_values, np.cumsum(d2v_pca.explained_variance_ratio_), lw=2, label='cumulative explained variance')\n",
    "ax.set_title('Doc2vec (DBOW + DMC) : explained variance of components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION: how many gram of DBOW and DMC?  ANSWER: they are both unigram (还没做bigram和trigram的部分）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图：蓝线表示每个pc component的解释力(explained_variance)，基本持平；橙线表示随着components增加，累计解释度（cumulative explained variance）基本趋于linear。以上说明不同component之间的解释力差别不大 --> not good (理想情况下是希望找到几个重要component能够有显著的解释度）。说明dimension reduction对这个data set的作用不大，一般PCA对numeric features来reduce dimensions表现较好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> TODO:  Part 9 (Neural Networks with Tfidf vectors using Keras) </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> ANN with Tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "819/818 [==============================] - 14s 17ms/step - loss: -0.3656 - acc: 0.5247 - val_loss: -1.5337 - val_acc: 0.5935\n",
      "Epoch 2/5\n",
      "819/818 [==============================] - 14s 17ms/step - loss: -2.2095 - acc: 0.6477 - val_loss: -2.1673 - val_acc: 0.6429\n",
      "Epoch 3/5\n",
      "819/818 [==============================] - 13s 15ms/step - loss: -2.7799 - acc: 0.6995 - val_loss: -2.3065 - val_acc: 0.6578\n",
      "Epoch 4/5\n",
      "819/818 [==============================] - 12s 15ms/step - loss: -3.0293 - acc: 0.7233 - val_loss: -2.3621 - val_acc: 0.6729\n",
      "Epoch 5/5\n",
      "819/818 [==============================] - 12s 15ms/step - loss: -3.1768 - acc: 0.7386 - val_loss: -2.3789 - val_acc: 0.6794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a38bb1cf8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch_generator(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    index = np.arange(np.shape(y_data)[0])\n",
    "    while 1:\n",
    "        index_batch = index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X_data[index_batch,:].toarray()\n",
    "        y_batch = y_data[y_data.index[index_batch]]\n",
    "        counter += 1\n",
    "        yield X_batch,y_batch\n",
    "        if (counter > number_of_batches):\n",
    "            counter=0\n",
    "            \n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=10000))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator=batch_generator(x_train_tfidf, train.Sentiment_encode.astype('int'), 32),\n",
    "                    epochs=5, validation_data=(x_test_tfidf, test.Sentiment_encode.astype('int')),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "again 注意命名 -> y_train: train.Sentiment_encode.astype('int') ; y_test: test.Sentiment_encode.astype('int')\n",
    "x_train: train.reviews; x_test: test.reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在5th epoch之后，validation accuracy达到最高值为0.679;显著小于logistic regression的validation accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "819/818 [==============================] - 16s 20ms/step - loss: -0.3441 - acc: 0.5351 - val_loss: -1.5177 - val_acc: 0.5924\n",
      "Epoch 2/5\n",
      "819/818 [==============================] - 16s 19ms/step - loss: -2.2079 - acc: 0.6474 - val_loss: -2.1684 - val_acc: 0.6417\n",
      "Epoch 3/5\n",
      "819/818 [==============================] - 16s 20ms/step - loss: -2.7811 - acc: 0.6994 - val_loss: -2.3088 - val_acc: 0.6580\n",
      "Epoch 4/5\n",
      "819/818 [==============================] - 15s 18ms/step - loss: -3.0308 - acc: 0.7232 - val_loss: -2.3637 - val_acc: 0.6709\n",
      "Epoch 5/5\n",
      "819/818 [==============================] - 14s 17ms/step - loss: -3.1758 - acc: 0.7383 - val_loss: -2.3830 - val_acc: 0.6786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a7548b4a8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try normalize input to see if yield better results\n",
    "from sklearn.preprocessing import Normalizer\n",
    "norm = Normalizer().fit(x_train_tfidf)\n",
    "x_train_tfidf_norm = norm.transform(x_train_tfidf)\n",
    "x_test_tfidf_norm = norm.transform(x_test_tfidf)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=10000))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator=batch_generator(x_train_tfidf_norm, train.Sentiment_encode.astype('int'), 32),\n",
    "                    epochs=5, validation_data=(x_test_tfidf_norm, test.Sentiment_encode.astype('int')),\n",
    "                    steps_per_epoch=x_train_tfidf_norm.shape[0]/32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize之后, validation accuracy反而下降了... 其实tf-idf vectorizer()过程中input就已经normalize了，因此之后无需再normalize一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "819/818 [==============================] - 15s 18ms/step - loss: -0.2704 - acc: 0.5131 - val_loss: -1.3914 - val_acc: 0.5807\n",
      "Epoch 2/5\n",
      "819/818 [==============================] - 13s 16ms/step - loss: -2.0752 - acc: 0.6367 - val_loss: -2.1224 - val_acc: 0.6378\n",
      "Epoch 3/5\n",
      "819/818 [==============================] - 13s 16ms/step - loss: -2.6875 - acc: 0.6915 - val_loss: -2.2939 - val_acc: 0.6556\n",
      "Epoch 4/5\n",
      "819/818 [==============================] - 13s 16ms/step - loss: -2.9531 - acc: 0.7148 - val_loss: -2.3672 - val_acc: 0.6659\n",
      "Epoch 5/5\n",
      "819/818 [==============================] - 13s 16ms/step - loss: -3.1071 - acc: 0.7302 - val_loss: -2.3922 - val_acc: 0.6763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a55689278>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: try add dropout layer to avoid overfitting to the training data\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(64, activation='relu', input_dim=10000))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.fit_generator(generator=batch_generator(x_train_tfidf, train.Sentiment_encode.astype('int'), 32),\n",
    "                    epochs=5, validation_data=(x_test_tfidf, test.Sentiment_encode.astype('int')),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "even adding dropout layer, the neural network model still underperform the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "819/818 [==============================] - 14s 18ms/step - loss: -0.3425 - acc: 0.5174 - val_loss: -1.5247 - val_acc: 0.5812\n",
      "Epoch 2/5\n",
      "819/818 [==============================] - 13s 15ms/step - loss: -2.2055 - acc: 0.6459 - val_loss: -2.1672 - val_acc: 0.6418\n",
      "Epoch 3/5\n",
      "819/818 [==============================] - 13s 16ms/step - loss: -2.7791 - acc: 0.6991 - val_loss: -2.3133 - val_acc: 0.6620\n",
      "Epoch 4/5\n",
      "819/818 [==============================] - 13s 16ms/step - loss: -3.0303 - acc: 0.7227 - val_loss: -2.3687 - val_acc: 0.6699\n",
      "Epoch 5/5\n",
      "819/818 [==============================] - 13s 15ms/step - loss: -3.1773 - acc: 0.7378 - val_loss: -2.3832 - val_acc: 0.6791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5751add8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: shuffling data --> another way to avoid overfitting\n",
    "\n",
    "def batch_generator_shuffle(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    index = np.arange(np.shape(y_data)[0])\n",
    "    np.random.shuffle(index)\n",
    "    while 1:\n",
    "        index_batch = index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X_data[index_batch,:].toarray()\n",
    "        y_batch = y_data[y_data.index[index_batch]]\n",
    "        counter += 1\n",
    "        yield X_batch,y_batch\n",
    "        if (counter > number_of_batches):\n",
    "            np.random.shuffle(index)\n",
    "            counter=0\n",
    "\n",
    "            \n",
    "model_s = Sequential()\n",
    "model_s.add(Dense(64, activation='relu', input_dim=10000))\n",
    "model_s.add(Dense(1, activation='sigmoid'))\n",
    "model_s.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_s.fit_generator(generator=batch_generator_shuffle(x_train_tfidf, train.Sentiment_encode.astype('int'), 32),\n",
    "                    epochs=5, validation_data=(x_test_tfidf, test.Sentiment_encode.astype('int')),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表现都差不多，仍然underperform logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Adjust Learning rate </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "819/818 [==============================] - 15s 19ms/step - loss: -1.4486 - acc: 0.6049 - val_loss: -2.1923 - val_acc: 0.6515\n",
      "Epoch 2/2\n",
      "819/818 [==============================] - 14s 18ms/step - loss: -2.8036 - acc: 0.7104 - val_loss: -2.2674 - val_acc: 0.6751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a588adf98>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# goal: to improve the performance of a neural net can be to adjust the learning rate\n",
    "import keras\n",
    "\n",
    "# Learning rate (lr) = 0.005\n",
    "custom_adam = keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "model_testing_2 = Sequential()\n",
    "model_testing_2.add(Dense(64, activation='relu', input_dim=10000))\n",
    "model_testing_2.add(Dense(1, activation='sigmoid'))\n",
    "model_testing_2.compile(optimizer=custom_adam,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_testing_2.fit_generator(generator=batch_generator_shuffle(x_train_tfidf, train.Sentiment_encode.astype('int'), 32),\n",
    "                    epochs=2, validation_data=(x_test_tfidf, test.Sentiment_encode.astype('int')),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "819/818 [==============================] - 16s 19ms/step - loss: 0.1760 - acc: 0.5025 - val_loss: -0.4058 - val_acc: 0.5652\n",
      "Epoch 2/2\n",
      "819/818 [==============================] - 15s 18ms/step - loss: -1.1442 - acc: 0.5876 - val_loss: -1.5639 - val_acc: 0.5904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a59248400>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try the same for the following learning rate:\n",
    "# Learning rate (lr) = 0.005\n",
    "# Learning rate (lr) = 0.01\n",
    "# Learning rate (lr) = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try adjust learning rate to (0.0005, 0.005, 0.01, 0.1) -> none of it outperform the default learning rate of 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> TODO: Increasing Number of Nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "819/818 [==============================] - 25s 31ms/step - loss: -0.6922 - acc: 0.5645 - val_loss: -1.9138 - val_acc: 0.6169\n",
      "Epoch 2/2\n",
      "819/818 [==============================] - 26s 31ms/step - loss: -2.5027 - acc: 0.6757 - val_loss: -2.2969 - val_acc: 0.6636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5a1ab748>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# goal is to improve performance\n",
    "\n",
    "model_s_2 = Sequential()\n",
    "model_s_2.add(Dense(128, activation='relu', input_dim=10000))\n",
    "model_s_2.add(Dense(1, activation='sigmoid'))\n",
    "model_s_2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_s_2.fit_generator(generator=batch_generator_shuffle(x_train_tfidf, train.Sentiment_encode.astype('int'), 32),\n",
    "                    epochs=2, validation_data=(x_test_tfidf, test.Sentiment_encode.astype('int')),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use 128 hidden nodes --> 即便如此，仍然underperform 一般的logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：As a result, in this particular case, neural network models failed to outperform logistic regression. This might be due to the high dimensionality and sparse characteristics of the textual data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> TODO:  implement a neural network with Doc2Vec vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Deeping Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Representation: Sequence Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "## Tokenize the sentences\n",
    "\n",
    "max_features = 276    # max length of reviews\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "# tokenizer.fit_on_texts(list(train_X)+list(test_X))\n",
    "tokenizer.fit_on_texts(list(X_train)+list(X_test))\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad Sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 276\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Embedding Enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will be using GLoVE Word2Vec embeddings to explain the enrichment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load glove index\n",
    "\n",
    "def load_glove_index():\n",
    "#     EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "    EMBEDDING_FILE = './input/glove.42B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:300]    # 选最常出现的300 words\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "    return embeddings_index\n",
    "\n",
    "glove_embedding_index = load_glove_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(glove_embedding_index.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create glove (add polarity and lowercase as well)\n",
    "\n",
    "def create_glove(word_index,embeddings_index):\n",
    "    emb_mean,emb_std = -0.005838499,0.48782197\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    embed_size = all_embs.shape[1]\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size+4))\n",
    "    \n",
    "    count_found = nb_words\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        word_sent = TextBlob(word).sentiment\n",
    "        # Extra information we are passing to our embeddings\n",
    "        extra_embed = [word_sent.polarity,word_sent.subjectivity]\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] =  np.append(embedding_vector,extra_embed)\n",
    "        else:\n",
    "            if word.islower():\n",
    "                embedding_vector = embeddings_index.get(word.capitalize())\n",
    "                if embedding_vector is not None: \n",
    "                    embedding_matrix[i] = np.append(embedding_vector,extra_embed)\n",
    "                else:\n",
    "                    embedding_matrix[i,300:] = extra_embed\n",
    "                    count_found-=1\n",
    "            else:\n",
    "                embedding_matrix[i,300:] = extra_embed\n",
    "                count_found-=1\n",
    "    print(\"Got embedding for \",count_found,\" words.\")\n",
    "    return embedding_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
